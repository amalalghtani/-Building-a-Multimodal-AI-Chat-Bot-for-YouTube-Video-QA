{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtLmsYYEjWNQ"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "import gradio as gr\n",
        "import yt_dlp\n",
        "from pydub import AudioSegment\n",
        "from faster_whisper import WhisperModel\n",
        "from langsmith import Client\n",
        "from langchain.callbacks.tracers.langchain import LangChainTracer\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "import openai\n",
        "# ‚úÖ LangSmith Setup\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "#os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "tracer = LangChainTracer(project_name=\"youtube-analyzer\")\n",
        "\n",
        "# ‚úÖ Global State\n",
        "segments = []\n",
        "full_text = \"\"\n",
        "bullet_summary = \"\"\n",
        "qa_chain = None\n",
        "\n",
        "# ‚úÖ Summarization\n",
        "def summarize_with_bullets(text):\n",
        "    prompt = f\"\"\"Summarize the following video transcript into **simple, concise bullet points** (around 5 to 10 bullets):\\n\\n{text[:3500]}\\n\\nRespond only with the bullet points, no introduction.\"\"\"\n",
        "    return ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, callbacks=[tracer]).invoke([HumanMessage(content=prompt)])\n",
        "\n",
        "# ‚úÖ Translation\n",
        "def summarize_and_translate(text):\n",
        "    summarization_prompt = f\"\"\"\n",
        "    Please summarize the following transcript into 7-10 clear bullet points:\n",
        "\n",
        "    {text[:3500]}\n",
        "\n",
        "    Respond only with the bullet points.\n",
        "    \"\"\"\n",
        "    summary = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, callbacks=[tracer]).invoke([HumanMessage(content=summarization_prompt)])\n",
        "\n",
        "    translation_prompt = f\"\"\"\n",
        "    Translate the following English bullet points into clear and natural Arabic (Fusha).\n",
        "    Avoid literal translation. Use professional tone and correct grammar:\n",
        "\n",
        "    {summary.content}\n",
        "    \"\"\"\n",
        "    translated = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, callbacks=[tracer]).invoke([HumanMessage(content=translation_prompt)])\n",
        "\n",
        "    return translated\n",
        "\n",
        "# ‚úÖ Transcription (Whisper without splitting)\n",
        "def transcribe_audio(audio_path):\n",
        "    global segments, full_text\n",
        "    audio = AudioSegment.from_mp3(audio_path)\n",
        "    duration_sec = len(audio) / 1000\n",
        "    print(f\"üéß Duration: {duration_sec:.2f} seconds\")\n",
        "\n",
        "    model = WhisperModel(\"base\", device=\"cpu\", compute_type=\"int8\")\n",
        "    result, _ = model.transcribe(audio_path)\n",
        "    segments = list(result)\n",
        "    full_text = \" \".join([seg.text for seg in segments])\n",
        "    return full_text\n",
        "\n",
        "# ‚úÖ Gradio Interface\n",
        "demo = gr.Blocks(title=\"üé• YouTube Analyzer\")\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    <div style=\"text-align: center; font-size: 24px; font-weight: bold; color: #0077b6;\">\n",
        "    üé• YouTube Video Analyzer\n",
        "    <br><span style=\"font-size: 16px;\">Paste a YouTube link and explore: Summary / Full Transcript / Translation / QA Chat.</span>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    video_url = gr.Textbox(label=\"üîó YouTube URL\")\n",
        "    process_btn = gr.Button(\"üöÄ Process Video\")\n",
        "    status = gr.Markdown()\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"üí¨ Chat About the Video\", height=350)\n",
        "\n",
        "    with gr.Row():\n",
        "        suggestion = gr.Radio([\"üìÑ Show Summary\", \"üìú Show Full Transcript\", \"üá® Translate to Arabic\"], label=\"Quick View\")\n",
        "\n",
        "    user_input = gr.Textbox(label=\"üí¨ Ask a Question\")\n",
        "    send_btn = gr.Button(\"üí¨ Send\")\n",
        "\n",
        "    # ‚úÖ MAIN VIDEO PROCESSING FUNCTION\n",
        "    def handle_video(video_url):\n",
        "        global qa_chain, full_text, bullet_summary, segments\n",
        "\n",
        "        try:\n",
        "            # üîÅ Reset all state\n",
        "            full_text = \"\"\n",
        "            bullet_summary = \"\"\n",
        "            segments = []\n",
        "            qa_chain = None\n",
        "\n",
        "            # üßπ Delete previous vector DB\n",
        "            if os.path.exists(\"./chroma_db\"):\n",
        "                shutil.rmtree(\"./chroma_db\")\n",
        "\n",
        "            yield \"üì• Downloading audio from YouTube...\"\n",
        "            audio_path = download_audio(video_url)\n",
        "            yield \"\"\n",
        "\n",
        "            yield \"üìù Transcribing audio...\"\n",
        "            full_text = transcribe_audio(audio_path)\n",
        "            yield \"\"\n",
        "\n",
        "            yield \"üìÑ Generating summary...\"\n",
        "            bullet_summary = summarize_with_bullets(full_text).content\n",
        "            yield \"\"\n",
        "\n",
        "            yield \"‚úÖ Done! You can now ask questions or explore the transcript.\"\n",
        "        except Exception as e:\n",
        "            yield f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "    # ‚úÖ BOT QA using RAG\n",
        "    def chat_with_bot(user_input, history):\n",
        "        global qa_chain, full_text\n",
        "\n",
        "        if not full_text.strip():\n",
        "            history.append((\"‚ùå Error\", \"‚ö†Ô∏è No transcript available. Please process a video first.\"))\n",
        "            return history, \"\"\n",
        "\n",
        "        try:\n",
        "            if qa_chain is None:\n",
        "                text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "                texts = text_splitter.create_documents([full_text])\n",
        "\n",
        "                embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "                db = Chroma.from_documents(texts, embedding=embeddings, persist_directory=\"./chroma_db\")\n",
        "\n",
        "                qa_chain = RetrievalQA.from_chain_type(\n",
        "                    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n",
        "                    retriever=db.as_retriever(),\n",
        "                    return_source_documents=False\n",
        "                )\n",
        "\n",
        "            response = qa_chain.run(user_input)\n",
        "            history.append((f\"**You:** {user_input}\", f\"**Bot:** {response}\"))\n",
        "            return history, \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            history.append((\"‚ùå Error\", f\"Something went wrong: {str(e)}\"))\n",
        "            return history, \"\"\n",
        "\n",
        "    # ‚úÖ Suggestions\n",
        "    def simulate_user_input(choice, history):\n",
        "        global bullet_summary, full_text\n",
        "        if choice == \"üìÑ Show Summary\":\n",
        "            history.append((\"üìÑ Show Summary\", bullet_summary or \"‚ùå Summary not ready.\"))\n",
        "        elif choice == \"üìú Show Full Transcript\":\n",
        "            history.append((\"üìú Show Full Transcript\", full_text or \"‚ùå Transcript not ready.\"))\n",
        "        elif choice == \"üá® Translate to Arabic\":\n",
        "            if full_text:\n",
        "                translated = summarize_and_translate(full_text).content\n",
        "                history.append((\"üá® Translate to Arabic\", translated))\n",
        "            else:\n",
        "                history.append((\"üá® Translate to Arabic\", \"‚ùå Transcript not ready.\"))\n",
        "        return history\n",
        "\n",
        "    # ‚úÖ Audio downloader\n",
        "    def download_audio(video_url):\n",
        "        if os.path.exists(\"audio.mp3\"):\n",
        "            os.remove(\"audio.mp3\")\n",
        "        ydl_opts = {\n",
        "            \"format\": \"bestaudio/best\",\n",
        "            \"outtmpl\": \"audio.%(ext)s\",\n",
        "            \"postprocessors\": [{\n",
        "                \"key\": \"FFmpegExtractAudio\",\n",
        "                \"preferredcodec\": \"mp3\",\n",
        "                \"preferredquality\": \"64\",\n",
        "            }],\n",
        "            'quiet': False,\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([video_url])\n",
        "        return \"audio.mp3\"\n",
        "\n",
        "    # ‚úÖ Events\n",
        "    process_btn.click(fn=handle_video, inputs=[video_url], outputs=status)\n",
        "    send_btn.click(fn=chat_with_bot, inputs=[user_input, chatbot], outputs=[chatbot, user_input])\n",
        "    suggestion.change(fn=simulate_user_input, inputs=[suggestion, chatbot], outputs=[chatbot])\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ]
}